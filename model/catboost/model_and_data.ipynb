{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16964aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 최상위 객체 타입 == <class 'dict'>\n",
      "\n",
      "== 딕셔너리 키 목록 ==\n",
      "['model', 'district_encoder', 'industry_encoder', 'sanggwon_encoder', 'X_train', 'y_train', 'X_test', 'y_test', 'feature_names']\n",
      "\n",
      "[model] 타입: <class 'catboost.core.CatBoostClassifier'>\n",
      " classes_ (앞 20개): [np.int64(0), np.int64(1)]\n",
      "\n",
      "[district_encoder] 타입: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      " classes_ (앞 20개): ['강남구', '강동구', '강북구', '강서구', '관악구', '광진구', '구로구', '금천구', '노원구', '도봉구', '동대문구', '동작구', '마포구', '서대문구', '서초구', '성동구', '성북구', '송파구', '양천구', '영등포구']\n",
      "\n",
      "[industry_encoder] 타입: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      " classes_ (앞 20개): ['PC방', '가구', '가방', '가전제품', '가전제품수리', '고시원', '골프연습장', '네일숍', '노래방', '당구장', '문구', '미곡판매', '미용실', '반찬가게', '부동산중개업', '분식전문점', '서적', '섬유제품', '세탁소', '수산물판매']\n",
      "\n",
      "[sanggwon_encoder] 타입: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      " classes_ (앞 20개): ['HH', 'HL', 'LH', 'LL']\n",
      "\n",
      "[feature_names] 타입: <class 'list'>\n",
      " feature_names[:20] = ['자치구_코드_명', '서비스_업종_코드_명', '점포_수', '유사_업종_점포_수', '개업_률', '개업_점포_수', '프랜차이즈_점포_수', '당월_매출_금액', '당월_매출_건수', '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액', '목요일_매출_금액', '금요일_매출_금액', '토요일_매출_금액', '일요일_매출_금액', '시간대_00_06_매출_금액', '시간대_06_11_매출_금액', '시간대_11_14_매출_금액', '시간대_14_17_매출_금액']\n",
      "\n",
      "요약 파일 저장: model_and_data_encoded.summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# inspect_pkl.py\n",
    "import joblib, pickle, sys, pprint, json, os\n",
    "from pathlib import Path\n",
    "\n",
    "# === 파일 경로 지정 ===\n",
    "PKL_PATH = Path(\"./model_and_data_encoded.pkl\")  # 또는 model_and_data.pkl\n",
    "\n",
    "# === 안전: 신뢰할 수 있는 파일만 언피클하세요! ===\n",
    "if not PKL_PATH.exists():\n",
    "    print(f\"파일 없음: {PKL_PATH.resolve()}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# joblib 우선, 실패 시 pickle로 시도\n",
    "try:\n",
    "    obj = joblib.load(PKL_PATH)\n",
    "except Exception as e:\n",
    "    print(\"[joblib.load 실패] -> pickle로 재시도:\", e)\n",
    "    with open(PKL_PATH, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "\n",
    "print(\"== 최상위 객체 타입 ==\", type(obj))\n",
    "\n",
    "# 딕셔너리일 가능성이 높음\n",
    "if isinstance(obj, dict):\n",
    "    print(\"\\n== 딕셔너리 키 목록 ==\")\n",
    "    print(list(obj.keys()))\n",
    "\n",
    "    # 주요 항목 미리보기\n",
    "    for key in (\"model\", \"district_encoder\", \"industry_encoder\", \"sanggwon_encoder\", \"feature_names\"):\n",
    "        if key in obj:\n",
    "            val = obj[key]\n",
    "            print(f\"\\n[{key}] 타입: {type(val)}\")\n",
    "            if key == \"feature_names\" and isinstance(val, (list, tuple)):\n",
    "                print(\" feature_names[:20] =\", val[:20])\n",
    "            if hasattr(val, \"classes_\"):\n",
    "                # 라벨인코더 계열\n",
    "                classes = getattr(val, \"classes_\", None)\n",
    "                if classes is not None:\n",
    "                    print(\" classes_ (앞 20개):\", list(classes)[:20])\n",
    "\n",
    "    # 원하면 텍스트로 덤프 저장\n",
    "    dump_path = PKL_PATH.with_suffix(\".summary.txt\")\n",
    "    with open(dump_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"== keys ==\\n\")\n",
    "        f.write(pprint.pformat(list(obj.keys())))\n",
    "        f.write(\"\\n\\n== feature_names (앞 100개) ==\\n\")\n",
    "        fn = obj.get(\"feature_names\", [])\n",
    "        f.write(pprint.pformat(fn[:100]))\n",
    "    print(f\"\\n요약 파일 저장: {dump_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"딕셔너리가 아닙니다. 속성 dir() 일부를 출력합니다.\")\n",
    "    attrs = [a for a in dir(obj) if not a.startswith(\"_\")]\n",
    "    print(attrs[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7b798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FILE: model_and_data.pkl  SIZE(KB): 76620.2  MD5: 76f283f8366acc39f71186b85bb3d272\n",
      "Loaded via: joblib\n",
      "Top: {'type': 'dict', 'n_keys': 5, 'sample_keys': {'model': 'CatBoostClassifier', 'X_train': 'DataFrame', 'y_train': 'Series', 'X_test': 'DataFrame', 'y_test': 'Series'}}\n",
      " - model: CatBoostClassifier\n",
      " - X_train: DataFrame\n",
      "   shape=(48244, 132), cols(sample)=['자치구_코드_명', '서비스_업종_코드_명', '점포_수', '유사_업종_점포_수', '개업_률', '개업_점포_수', '프랜차이즈_점포_수', '당월_매출_금액', '당월_매출_건수', '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액']\n",
      " - y_train: Series\n",
      "================================================================================\n",
      "FILE: model_and_data_encoded.pkl  SIZE(KB): 76626.4  MD5: 58d9dc00da265eaa23b2a76cb8c1f70d\n",
      "Loaded via: joblib\n",
      "Top: {'type': 'dict', 'n_keys': 9, 'sample_keys': {'model': 'CatBoostClassifier', 'district_encoder': 'LabelEncoder', 'industry_encoder': 'LabelEncoder', 'sanggwon_encoder': 'LabelEncoder', 'X_train': 'DataFrame', 'y_train': 'Series', 'X_test': 'DataFrame', 'y_test': 'Series', 'feature_names': 'list'}}\n",
      " - model: CatBoostClassifier\n",
      " - district_encoder: LabelEncoder\n",
      " - industry_encoder: LabelEncoder\n",
      " - sanggwon_encoder: LabelEncoder\n",
      " - X_train: DataFrame\n",
      "   shape=(48244, 132), cols(sample)=['자치구_코드_명', '서비스_업종_코드_명', '점포_수', '유사_업종_점포_수', '개업_률', '개업_점포_수', '프랜차이즈_점포_수', '당월_매출_금액', '당월_매출_건수', '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액']\n",
      " - y_train: Series\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.7.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib, pickle, pandas as pd, os, sys, inspect, hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "paths = [\n",
    "    Path(\"model_and_data.pkl\"),\n",
    "    Path(\"model_and_data_encoded.pkl\"),\n",
    "]\n",
    "\n",
    "def md5(path):\n",
    "    import hashlib\n",
    "    h = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_any(path):\n",
    "    try:\n",
    "        return joblib.load(path), \"joblib\"\n",
    "    except Exception as e1:\n",
    "        with open(path, \"rb\") as f:\n",
    "            try:\n",
    "                return pickle.load(f), \"pickle\"\n",
    "            except Exception as e2:\n",
    "                print(f\"[!] Load failed: {path.name}\\n joblib: {repr(e1)}\\n pickle: {repr(e2)}\")\n",
    "                return None, \"error\"\n",
    "\n",
    "def describe(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        keys = list(obj.keys())\n",
    "        sample = {k: type(obj[k]).__name__ for k in keys[:15]}\n",
    "        return {\"type\":\"dict\",\"n_keys\":len(keys),\"sample_keys\":sample}\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        seq = list(obj)\n",
    "        return {\"type\":type(obj).__name__,\"length\":len(seq),\"sample_types\":[type(x).__name__ for x in seq[:10]]}\n",
    "    else:\n",
    "        t = type(obj)\n",
    "        out = {\"type\": t.__name__, \"module\": getattr(t, \"__module__\", \"?\")}\n",
    "        for a in [\"classes_\", \"n_features_in_\", \"feature_names_in_\", \"best_params_\"]:\n",
    "            if hasattr(obj, a):\n",
    "                v = getattr(obj, a)\n",
    "                out[a] = (v if isinstance(v, (int, float, str)) else f\"{type(v).__name__}\")\n",
    "        return out\n",
    "\n",
    "for p in paths:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"FILE: {p.name}  SIZE(KB): {p.stat().st_size/1024:.1f}  MD5: {md5(p)}\")\n",
    "    obj, how = load_any(p)\n",
    "    print(\"Loaded via:\", how)\n",
    "    if obj is None: \n",
    "        continue\n",
    "    top = describe(obj)\n",
    "    print(\"Top:\", top)\n",
    "    if isinstance(obj, dict):\n",
    "        # 자주 쓰는 키 힌트\n",
    "        for k in [\"model\",\"final_model\",\"clf\",\"pipeline\",\"district_encoder\",\"industry_encoder\",\"sanggwon_encoder\",\"X\",\"y\",\"X_train\",\"y_train\",\"X_val\",\"y_val\"]:\n",
    "            if k in obj:\n",
    "                print(f\" - {k}: {type(obj[k]).__name__}\")\n",
    "                try:\n",
    "                    if isinstance(obj[k], pd.DataFrame):\n",
    "                        print(f\"   shape={obj[k].shape}, cols(sample)={obj[k].columns[:12].tolist()}\")\n",
    "                except Exception:\n",
    "                    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbd6400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 최상위 객체 타입 == <class 'dict'>\n",
      "\n",
      "== 딕셔너리 키 목록 ==\n",
      "['model', 'X_train', 'y_train', 'X_test', 'y_test']\n",
      "\n",
      "[model] 타입: <class 'catboost.core.CatBoostClassifier'>\n",
      " classes_ (앞 20개): [np.int64(0), np.int64(1)]\n",
      "\n",
      "요약 파일 저장: model_and_data.summary.txt\n"
     ]
    }
   ],
   "source": [
    "# inspect_pkl.py\n",
    "import joblib, pickle, sys, pprint, json, os\n",
    "from pathlib import Path\n",
    "\n",
    "# === 파일 경로 지정 ===\n",
    "PKL_PATH = Path(\"./model_and_data.pkl\")\n",
    "\n",
    "# === 안전: 신뢰할 수 있는 파일만 언피클하세요! ===\n",
    "if not PKL_PATH.exists():\n",
    "    print(f\"파일 없음: {PKL_PATH.resolve()}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# joblib 우선, 실패 시 pickle로 시도\n",
    "try:\n",
    "    obj = joblib.load(PKL_PATH)\n",
    "except Exception as e:\n",
    "    print(\"[joblib.load 실패] -> pickle로 재시도:\", e)\n",
    "    with open(PKL_PATH, \"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "\n",
    "print(\"== 최상위 객체 타입 ==\", type(obj))\n",
    "\n",
    "# 딕셔너리일 가능성이 높음\n",
    "if isinstance(obj, dict):\n",
    "    print(\"\\n== 딕셔너리 키 목록 ==\")\n",
    "    print(list(obj.keys()))\n",
    "\n",
    "    # 주요 항목 미리보기\n",
    "    for key in (\"model\", \"district_encoder\", \"industry_encoder\", \"sanggwon_encoder\", \"feature_names\"):\n",
    "        if key in obj:\n",
    "            val = obj[key]\n",
    "            print(f\"\\n[{key}] 타입: {type(val)}\")\n",
    "            if key == \"feature_names\" and isinstance(val, (list, tuple)):\n",
    "                print(\" feature_names[:20] =\", val[:20])\n",
    "            if hasattr(val, \"classes_\"):\n",
    "                # 라벨인코더 계열\n",
    "                classes = getattr(val, \"classes_\", None)\n",
    "                if classes is not None:\n",
    "                    print(\" classes_ (앞 20개):\", list(classes)[:20])\n",
    "\n",
    "    # 원하면 텍스트로 덤프 저장\n",
    "    dump_path = PKL_PATH.with_suffix(\".summary.txt\")\n",
    "    with open(dump_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"== keys ==\\n\")\n",
    "        f.write(pprint.pformat(list(obj.keys())))\n",
    "        f.write(\"\\n\\n== feature_names (앞 100개) ==\\n\")\n",
    "        fn = obj.get(\"feature_names\", [])\n",
    "        f.write(pprint.pformat(fn[:100]))\n",
    "    print(f\"\\n요약 파일 저장: {dump_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"딕셔너리가 아닙니다. 속성 dir() 일부를 출력합니다.\")\n",
    "    attrs = [a for a in dir(obj) if not a.startswith(\"_\")]\n",
    "    print(attrs[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
